#!/usr/bin/env python3
# filepath: admin/security/incident_response_kit/malware_containment.py
"""
Malware Containment Module for Incident Response Toolkit

This module provides functionality for containing and isolating malware during
security incidents. It supports analysis and containment of potentially malicious
files and processes across systems, while maintaining forensic integrity and
chain of custody for all operations.
"""

# Standard library imports
import os
import sys
import logging
import json
import shutil
import tempfile
import argparse
import subprocess
import time
import signal
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union, Any, Set

# Third-party imports
import psutil

# Setup module logging
logger = logging.getLogger(__name__)

# File-related constants
SAFE_EXTENSIONS = {'.txt', '.log', '.json', '.csv', '.xml', '.md', '.yml', '.yaml'}
HIGH_RISK_EXTENSIONS = {'.exe', '.dll', '.bat', '.ps1', '.vbs', '.js', '.hta', '.scr', '.pif', '.com'}
QUARANTINE_PERMISSIONS = 0o600  # Read/write only by owner

# Path constants
MODULE_PATH = Path(os.path.dirname(os.path.abspath(__file__)))
DEFAULT_QUARANTINE_DIR = MODULE_PATH / "quarantine"
DEFAULT_CONFIG_PATH = MODULE_PATH / "config" / "response_config.json"

# Exception classes
class MalwareContainmentError(Exception):
    """Base exception for all malware containment errors."""
    pass

class QuarantineError(MalwareContainmentError):
    """Error during file quarantine operations."""
    pass

class AnalysisError(MalwareContainmentError):
    """Error during malware analysis operations."""
    pass

class ValidationError(MalwareContainmentError):
    """Error during validation of parameters or files."""
    pass


class MalwareContainment:
    """
    Main class for malware containment operations during incident response.

    This class provides methods for:
    - Safely quarantining suspected malicious files
    - Basic static analysis of suspicious files
    - Process containment for active malware
    - Memory acquisition from infected systems
    - Integration with external analysis tools
    """

    # Initialization and setup methods
    def __init__(self,
                incident_id: Optional[str] = None,
                quarantine_dir: Optional[str] = None,
                config_path: Optional[str] = None,
                analyst: Optional[str] = None,
                log_level: int = logging.INFO,
                integrity_check: bool = True):
        """
        Initialize the malware containment environment.

        Args:
            incident_id: Unique identifier for the incident
            quarantine_dir: Directory to store quarantined files
            config_path: Path to configuration file
            analyst: Name of the analyst performing the action
            log_level: Logging level
            integrity_check: Whether to verify toolkit integrity
        """
        self.incident_id = incident_id or f"IR-{int(time.time())}"
        self.quarantine_dir = Path(quarantine_dir or DEFAULT_QUARANTINE_DIR)
        self.config_path = Path(config_path or DEFAULT_CONFIG_PATH)
        self.analyst = analyst or os.getenv("USER", "unknown")
        self.integrity_verified = False

        # Setup logging
        self._setup_logging(log_level)

        # Load configuration
        self.config = self._load_config()

        # Create quarantine directory if it doesn't exist
        self._setup_quarantine_dir()

        # Verify toolkit integrity if requested
        if integrity_check:
            self.verify_integrity()

    def _setup_logging(self, log_level: int) -> None:
        """Configure logging for the module."""
        self.logger = logging.getLogger(f"{__name__}.{self.incident_id}")
        self.logger.setLevel(log_level)

        # Add console handler if not already present
        if not self.logger.handlers:
            console_handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
                datefmt='%Y-%m-%d %H:%M:%S'
            )
            console_handler.setFormatter(formatter)
            self.logger.addHandler(console_handler)

        self.logger.info(f"Malware containment initialized for incident: {self.incident_id}")

    def _load_config(self) -> Dict[str, Any]:
        """Load configuration from the config file."""
        try:
            if self.config_path.exists():
                with open(self.config_path, 'r') as f:
                    config = json.load(f)
                self.logger.debug(f"Loaded configuration from {self.config_path}")
                return config
            else:
                self.logger.warning(f"Configuration file not found: {self.config_path}")
                return {
                    "quarantine": {
                        "max_size_mb": 500,
                        "encrypt": True,
                        "encrypt_method": "aes-256-cbc"
                    },
                    "analysis": {
                        "static_only": True,
                        "use_external_tools": True,
                        "yara_rules_dir": str(MODULE_PATH.parent / "forensic_tools" / "yara_rules")
                    },
                    "process_isolation": {
                        "default_method": "suspend",
                        "allowed_methods": ["suspend", "terminate", "isolate"]
                    }
                }
        except (json.JSONDecodeError, IOError) as e:
            self.logger.error(f"Error loading configuration: {e}")
            return {}

    def _setup_quarantine_dir(self) -> None:
        """Create and secure the quarantine directory."""
        if not self.quarantine_dir.exists():
            try:
                self.quarantine_dir.mkdir(parents=True, mode=0o700)
                self.logger.info(f"Created quarantine directory: {self.quarantine_dir}")
            except (IOError, OSError) as e:
                raise QuarantineError(f"Failed to create quarantine directory: {e}")

        # Create incident-specific subdirectory
        self.incident_quarantine_dir = self.quarantine_dir / self.incident_id
        if not self.incident_quarantine_dir.exists():
            try:
                self.incident_quarantine_dir.mkdir(parents=True, mode=0o700)
                self.logger.info(f"Created incident quarantine directory: {self.incident_quarantine_dir}")
            except (IOError, OSError) as e:
                raise QuarantineError(f"Failed to create incident quarantine directory: {e}")

    def verify_integrity(self) -> bool:
        """
        Verify the integrity of the toolkit components.

        Returns:
            bool: True if integrity check passed, False otherwise
        """
        self.logger.info("Verifying toolkit integrity...")

        try:
            # Define paths to critical files
            critical_files = [
                MODULE_PATH / "malware_containment.py",
                MODULE_PATH / "network_isolation.py",
                MODULE_PATH / "forensic_tools" / "file_integrity.py",
                MODULE_PATH / "config" / "response_config.json"
            ]

            # Try to import file integrity from forensic_tools if available
            try:
                sys.path.insert(0, str(MODULE_PATH))
                from forensic_tools.file_integrity import verify_file_integrity

                for file_path in critical_files:
                    if file_path.exists():
                        if not verify_file_integrity(file_path):
                            self.logger.error(f"Integrity check failed for {file_path}")
                            return False

                self.integrity_verified = True
                self.logger.info("Toolkit integrity verification successful")
                return True
            except ImportError:
                self.logger.warning("Could not import file_integrity module for verification")

                # Fallback to simple existence check if verification module not available
                for file_path in critical_files:
                    if not file_path.exists():
                        self.logger.warning(f"Critical file missing: {file_path}")

                self.logger.info("Basic file existence check completed")
                self.integrity_verified = True
                return True

        except Exception as e:
            self.logger.error(f"Error during integrity verification: {e}")
            return False

    # Core functionality methods
    def quarantine_file(self,
                        file_path: str,
                        metadata: Optional[Dict[str, Any]] = None,
                        encrypt: Optional[bool] = None) -> Dict[str, Any]:
        """
        Quarantine a suspected malicious file.

        Args:
            file_path: Path to the file to quarantine
            metadata: Additional metadata about the file
            encrypt: Whether to encrypt the quarantined file

        Returns:
            Dict containing quarantine information including the new location

        Raises:
            QuarantineError: If quarantine operation fails
        """
        # Validate file path
        try:
            file_path = Path(file_path).resolve(strict=True)
        except (TypeError, ValueError, RuntimeError) as e:
            raise QuarantineError(f"Invalid file path: {e}")

        if not file_path.exists():
            raise QuarantineError(f"File not found: {file_path}")

        if not file_path.is_file():
            raise QuarantineError(f"Not a regular file: {file_path}")

        self.logger.info(f"Quarantining file: {file_path}")

        # Generate quarantine file name with timestamp
        timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
        safe_name = self._sanitize_filename(file_path.name)
        quarantine_name = f"{timestamp}_{safe_name}"
        quarantine_path = self.incident_quarantine_dir / quarantine_name

        # Create metadata
        result = {
            "original_path": str(file_path),
            "quarantine_path": str(quarantine_path),
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "analyst": self.analyst,
            "incident_id": self.incident_id,
            "file_size": file_path.stat().st_size,
            "file_name": file_path.name
        }

        # Calculate hashes
        try:
            result.update(self.calculate_hashes(file_path))
        except Exception as e:
            self.logger.warning(f"Could not calculate file hashes: {e}")

        # Check file size against max size
        max_size_mb = self.config.get('quarantine', {}).get('max_size_mb', 500)
        if file_path.stat().st_size > max_size_mb * 1024 * 1024:
            self.logger.warning(f"File exceeds maximum quarantine size ({max_size_mb}MB)")
            result["status"] = "failed"
            result["reason"] = f"File exceeds maximum quarantine size ({max_size_mb}MB)"
            return result

        # Add custom metadata
        if metadata:
            result["metadata"] = metadata

        # Determine encryption setting
        should_encrypt = encrypt if encrypt is not None else self.config.get('quarantine', {}).get('encrypt', False)

        try:
            # Copy the file to quarantine with secure permissions
            shutil.copy2(file_path, quarantine_path)
            os.chmod(quarantine_path, QUARANTINE_PERMISSIONS)

            # Encrypt the file if requested
            if should_encrypt:
                encrypt_result = self._encrypt_quarantined_file(quarantine_path)
                result["encrypted"] = encrypt_result.get("success", False)
                if encrypt_result.get("success"):
                    quarantine_path = encrypt_result.get("encrypted_path")
                    result["quarantine_path"] = str(quarantine_path)

            # Save metadata file
            metadata_path = quarantine_path.with_suffix('.meta.json')
            with open(metadata_path, 'w') as f:
                json.dump(result, f, indent=2)
            os.chmod(metadata_path, QUARANTINE_PERMISSIONS)

            # Update result status
            result["status"] = "success"
            self.logger.info(f"File successfully quarantined at {quarantine_path}")

            # Update quarantine index
            self._update_quarantine_index(result)

            return result

        except (IOError, OSError) as e:
            self.logger.error(f"Error quarantining file: {e}")
            result["status"] = "failed"
            result["reason"] = str(e)
            return result

    def restore_quarantined_file(self,
                                quarantine_path: str,
                                restore_path: Optional[str] = None,
                                decrypt: bool = True) -> Dict[str, Any]:
        """
        Restore a file from quarantine.

        Args:
            quarantine_path: Path to the quarantined file
            restore_path: Path where the file should be restored (None for original location)
            decrypt: Whether to decrypt the file if encrypted

        Returns:
            Dict with restoration result
        """
        quarantine_path = Path(quarantine_path)
        if not quarantine_path.exists():
            raise QuarantineError(f"Quarantined file not found: {quarantine_path}")

        # Look for metadata file
        metadata_path = quarantine_path.with_suffix('.meta.json')
        if not metadata_path.exists():
            alternative_path = Path(str(quarantine_path) + '.meta.json')
            if alternative_path.exists():
                metadata_path = alternative_path
            else:
                raise QuarantineError(f"Metadata file not found for {quarantine_path}")

        # Load metadata
        try:
            with open(metadata_path, 'r') as f:
                metadata = json.load(f)
        except (json.JSONDecodeError, IOError) as e:
            raise QuarantineError(f"Error reading metadata: {e}")

        # Determine restore path
        if not restore_path:
            restore_path = metadata.get("original_path")
            if not restore_path:
                raise QuarantineError("Original file path not found in metadata")

        restore_path = Path(restore_path)

        # Create result dictionary
        result = {
            "quarantine_path": str(quarantine_path),
            "restore_path": str(restore_path),
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "analyst": self.analyst,
            "incident_id": self.incident_id
        }

        try:
            # Handle decryption if needed
            file_to_restore = quarantine_path
            if metadata.get("encrypted", False) and decrypt:
                # Check which encryption method was used
                if metadata.get("method") == "core.security.cs_crypto":
                    try:
                        from core.security.cs_crypto import decrypt_file
                        with tempfile.NamedTemporaryFile(delete=False) as temp_file:
                            temp_path = Path(temp_file.name)
                        decrypt_file(quarantine_path, temp_path)
                        file_to_restore = temp_path
                    except ImportError:
                        raise QuarantineError("Decryption module not available")
                elif metadata.get("method") == "openssl":
                    password_file = self.incident_quarantine_dir / ".encryption_key"
                    if not password_file.exists():
                        raise QuarantineError("Encryption key not found")

                    with tempfile.NamedTemporaryFile(delete=False) as temp_file:
                        temp_path = Path(temp_file.name)

                    with open(password_file, 'r') as f:
                        password = f.read().strip()

                    # Use OpenSSL for decryption
                    openssl_cmd = [
                        "openssl", "enc", "-d", "-aes-256-cbc",
                        "-in", str(quarantine_path),
                        "-out", str(temp_path),
                        "-pass", f"pass:{password}"
                    ]

                    subprocess.run(openssl_cmd, check=True, capture_output=True)
                    file_to_restore = temp_path
                else:
                    raise QuarantineError(f"Unknown encryption method: {metadata.get('method')}")

            # Create directory if it doesn't exist
            os.makedirs(restore_path.parent, exist_ok=True)

            # Copy the file to its restore location
            shutil.copy2(file_to_restore, restore_path)

            # Clean up temporary files if they were created
            if file_to_restore != quarantine_path:
                os.unlink(file_to_restore)

            # Update the restoration record
            result["status"] = "success"
            result["file_hash"] = self.calculate_hashes(restore_path).get("sha256")

            self.logger.info(f"Successfully restored file to {restore_path}")
            return result

        except Exception as e:
            self.logger.error(f"Error restoring file: {e}")
            result["status"] = "failed"
            result["error"] = str(e)
            return result

    def list_quarantined_files(self) -> List[Dict[str, Any]]:
        """
        List all quarantined files for the current incident.

        Returns:
            List of quarantined file records
        """
        if not self.incident_quarantine_dir.exists():
            return []

        quarantine_records = []

        # Look for metadata files
        for metadata_file in self.incident_quarantine_dir.glob("*.meta.json"):
            try:
                with open(metadata_file, 'r') as f:
                    record = json.load(f)
                    quarantine_records.append(record)
            except (json.JSONDecodeError, IOError) as e:
                self.logger.warning(f"Error reading quarantine metadata file {metadata_file}: {e}")

        return quarantine_records

    def contains_malware_signatures(self, file_path: str) -> Dict[str, Any]:
        """
        Check if a file contains known malware signatures.

        This is a simplified wrapper around the full analysis.

        Args:
            file_path: Path to the file to check

        Returns:
            Dict with signature match results
        """
        self.logger.info(f"Checking file for malware signatures: {file_path}")

        try:
            # Perform basic analysis
            analysis_results = self.analyze_file(file_path, detailed=False)

            # Prepare simplified result
            result = {
                "file_path": file_path,
                "contains_signatures": False,
                "risk_level": analysis_results.get("risk_level", "unknown"),
                "signatures_found": []
            }

            # Check for YARA matches
            if analysis_results.get("yara_matches"):
                result["contains_signatures"] = True
                for match in analysis_results.get("yara_matches", []):
                    result["signatures_found"].append({
                        "name": match.get("rule"),
                        "type": "yara",
                        "tags": match.get("tags", []),
                        "meta": match.get("meta", {})
                    })

            return result

        except Exception as e:
            self.logger.error(f"Error checking for malware signatures: {e}")
            return {
                "file_path": file_path,
                "error": str(e),
                "contains_signatures": False,
                "risk_level": "error"
            }

    # Analysis methods
    def analyze_file(self, file_path: str, detailed: bool = False) -> Dict[str, Any]:
        """
        Perform static analysis on a suspicious file.

        Args:
            file_path: Path to the file to analyze
            detailed: Whether to perform detailed analysis

        Returns:
            Dict containing analysis results
        """
        file_path = Path(file_path)
        if not file_path.exists():
            raise AnalysisError(f"File not found: {file_path}")

        self.logger.info(f"Analyzing file: {file_path}")

        # Initialize result with basic file info
        result = {
            "file_path": str(file_path),
            "file_name": file_path.name,
            "file_size": file_path.stat().st_size,
            "analysis_time": datetime.now(timezone.utc).isoformat(),
            "analyst": self.analyst,
            "incident_id": self.incident_id
        }

        # Calculate file hashes
        try:
            result.update(self.calculate_hashes(file_path))
        except Exception as e:
            self.logger.warning(f"Hash calculation failed: {e}")
            result["hash_error"] = str(e)

        # Determine file type
        result.update(self._get_file_type(file_path))

        # Check for known dangerous extensions
        extension = file_path.suffix.lower()
        result["high_risk_extension"] = extension in HIGH_RISK_EXTENSIONS

        # Extract strings for basic analysis
        try:
            result.update(self._extract_strings(file_path))
        except Exception as e:
            self.logger.warning(f"String extraction failed: {e}")
            result["strings_error"] = str(e)

        # Perform YARA scan if available
        try:
            yara_results = self._scan_with_yara(file_path)
            if yara_results:
                result["yara_matches"] = yara_results
                result["malicious_indicators"] = len(yara_results)
        except Exception as e:
            self.logger.warning(f"YARA scan failed: {e}")
            result["yara_error"] = str(e)

        # Perform detailed analysis if requested
        if detailed:
            try:
                result.update(self._perform_detailed_analysis(file_path))
            except Exception as e:
                self.logger.warning(f"Detailed analysis failed: {e}")
                result["detailed_analysis_error"] = str(e)

        # Assess risk level
        result["risk_level"] = self._assess_risk_level(result)

        self.logger.info(f"Analysis completed. Risk level: {result['risk_level']}")
        return result

    def calculate_hashes(self, file_path: Path) -> Dict[str, str]:
        """
        Calculate cryptographic hashes for a file.

        Args:
            file_path: Path to the file

        Returns:
            Dict containing various hash values
        """
        import hashlib

        result = {}

        with open(file_path, 'rb') as f:
            content = f.read()

            # Calculate common hashes
            result["md5"] = hashlib.md5(content).hexdigest()
            result["sha1"] = hashlib.sha1(content).hexdigest()
            result["sha256"] = hashlib.sha256(content).hexdigest()

            # Try to calculate ssdeep hash if available
            try:
                import ssdeep
                result["ssdeep"] = ssdeep.hash(content)
            except ImportError:
                pass

        return result

    # Process manipulation methods
    def isolate_process(self,
                       pid: int,
                       method: Optional[str] = None,
                       force: bool = False) -> Dict[str, Any]:
        """
        Isolate a potentially malicious process.

        Args:
            pid: Process ID to isolate
            method: Isolation method (suspend, terminate, isolate)
            force: Whether to force termination for critical processes

        Returns:
            Dict with isolation result
        """
        # Get default method if not specified
        if not method:
            method = self.config.get("process_isolation", {}).get("default_method", "suspend")

        # Validate method
        allowed_methods = self.config.get("process_isolation", {}).get(
            "allowed_methods", ["suspend", "terminate", "isolate"])

        if method not in allowed_methods:
            raise ValidationError(f"Invalid isolation method: {method}")

        self.logger.info(f"Isolating process {pid} using method: {method}")

        result = {
            "pid": pid,
            "method": method,
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "analyst": self.analyst,
            "incident_id": self.incident_id
        }

        try:
            # Get process info before taking action
            result["process_info"] = self._get_process_info(pid)

            # Perform the isolation based on method
            if method == "suspend":
                if sys.platform == "win32":
                    # Windows-specific suspension
                    try:
                        import ctypes

                        # Define NtSuspendProcess function if it's not available directly
                        try:
                            # First try to access NtSuspendProcess directly
                            kernel32 = ctypes.windll.kernel32
                            ntdll = ctypes.windll.ntdll
                            NtSuspendProcess = ntdll.NtSuspendProcess
                        except (AttributeError, WindowsError):
                            # If not available, load it dynamically
                            ntdll = ctypes.WinDLL('ntdll.dll')
                            NtSuspendProcess = getattr(ntdll, 'NtSuspendProcess')
                            # Set the correct function prototype
                            NtSuspendProcess.argtypes = [ctypes.c_void_p]
                            NtSuspendProcess.restype = ctypes.c_ulong

                        # Open the process with the appropriate access rights
                        PROCESS_SUSPEND_RESUME = 0x0800
                        handle = kernel32.OpenProcess(PROCESS_SUSPEND_RESUME, False, pid)

                        if handle:
                            # Suspend the process
                            NtSuspendProcess(handle)
                            kernel32.CloseHandle(handle)
                            result["status"] = "success"
                            self.logger.info(f"Successfully suspended process {pid}")
                        else:
                            error_code = kernel32.GetLastError()
                            result["status"] = "failed"
                            result["error"] = f"Could not open process {pid} (Error code: {error_code})"
                            self.logger.error(f"Failed to open process {pid}, error code: {error_code}")
                    except Exception as e:
                        result["status"] = "failed"
                        result["error"] = f"Failed to suspend process: {str(e)}"
                        self.logger.error(f"Exception during process suspension: {str(e)}")
                else:
                    # Unix-like systems use SIGSTOP
                    try:
                        os.kill(pid, signal.SIGSTOP)
                        result["status"] = "success"
                        self.logger.info(f"Successfully sent SIGSTOP to process {pid}")
                    except Exception as e:
                        result["status"] = "failed"
                        result["error"] = f"Failed to send SIGSTOP: {str(e)}"

            elif method == "terminate":
                # Check if it's a critical system process
                if not force and self._is_critical_process(result["process_info"]):
                    result["status"] = "failed"
                    result["error"] = "Refusing to terminate critical system process. Use force=True to override."
                else:
                    if sys.platform == "win32":
                        # Windows termination
                        subprocess.run(["taskkill", "/F", "/PID", str(pid)], check=True)
                    else:
                        # Unix-like termination
                        os.kill(pid, signal.SIGKILL)
                    result["status"] = "success"

            elif method == "isolate":
                # This would use network isolation techniques
                # Import network isolation capabilities if available
                try:
                    from .network_isolation import isolate_process_network
                    isolation = isolate_process_network(pid, incident_id=self.incident_id)
                    result.update(isolation)
                except ImportError:
                    result["status"] = "failed"
                    result["error"] = "Network isolation module not available"

        except ProcessLookupError:
            result["status"] = "failed"
            result["error"] = f"Process {pid} not found"
        except PermissionError:
            result["status"] = "failed"
            result["error"] = f"Permission denied for process {pid}"
        except Exception as e:
            result["status"] = "failed"
            result["error"] = str(e)

        self.logger.info(f"Process isolation result: {result['status']}")
        return result

    # Utility methods
    def _encrypt_quarantined_file(self, file_path: Path) -> Dict[str, Any]:
        """
        Encrypt a quarantined file.

        Args:
            file_path: Path to the file to encrypt

        Returns:
            Dict containing encryption result
        """
        result = {
            "success": False,
            "original_path": str(file_path),
        }

        # Check if encryption tools are available
        try:
            # Try to import from core.security if available
            try:
                from core.security.cs_crypto import encrypt_file
                encrypted_path = file_path.with_suffix('.encrypted')
                encrypt_file(file_path, encrypted_path)
                result["success"] = True
                result["encrypted_path"] = str(encrypted_path)
                result["method"] = "core.security.cs_crypto"

                # Remove original file after successful encryption
                os.unlink(file_path)

            except ImportError:
                # Fallback to using openssl command line
                encrypted_path = file_path.with_suffix('.enc')
                password_file = self.incident_quarantine_dir / ".encryption_key"

                # Generate encryption key if it doesn't exist
                if not password_file.exists():
                    import secrets
                    with open(password_file, 'w') as f:
                        f.write(secrets.token_hex(32))
                    os.chmod(password_file, 0o600)

                # Use OpenSSL for encryption
                with open(password_file, 'r') as f:
                    password = f.read().strip()

                openssl_cmd = [
                    "openssl", "enc", "-aes-256-cbc", "-salt",
                    "-in", str(file_path),
                    "-out", str(encrypted_path),
                    "-pass", f"pass:{password}"
                ]

                subprocess.run(openssl_cmd, check=True, capture_output=True)

                if encrypted_path.exists():
                    result["success"] = True
                    result["encrypted_path"] = str(encrypted_path)
                    result["method"] = "openssl"

                    # Remove original file after successful encryption
                    os.unlink(file_path)

        except Exception as e:
            self.logger.error(f"Encryption failed: {e}")
            result["error"] = str(e)

        return result

    def _update_quarantine_index(self, quarantine_record: Dict[str, Any]) -> None:
        """Update the quarantine index with a new entry."""
        index_path = self.quarantine_dir / "quarantine_index.jsonl"
        try:
            with open(index_path, 'a') as f:
                f.write(json.dumps(quarantine_record) + "\n")
            os.chmod(index_path, QUARANTINE_PERMISSIONS)
        except (IOError, OSError) as e:
            self.logger.error(f"Failed to update quarantine index: {e}")

    def _sanitize_filename(self, filename: str) -> str:
        """Sanitize a filename for safe storage."""
        # Replace potentially dangerous characters
        safe_chars = set("abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789._-")
        return ''.join(c if c in safe_chars else '_' for c in filename)

    def _get_file_type(self, file_path: Path) -> Dict[str, Any]:
        """Determine file type using various methods."""
        result = {}

        # Use file command if available
        try:
            file_output = subprocess.run(
                ["file", "-b", str(file_path)],
                capture_output=True,
                text=True,
                check=True
            ).stdout.strip()
            result["file_type"] = file_output
        except (subprocess.SubprocessError, FileNotFoundError):
            # Fallback to extension-based guess
            result["file_type"] = f"Unknown (extension: {file_path.suffix})"

        # Check if file is executable
        result["is_executable"] = os.access(file_path, os.X_OK)

        # Check if file might be a script
        with open(file_path, 'rb') as f:
            header = f.read(4096)

            # Check for script headers
            if header.startswith(b'#!'):
                result["is_script"] = True
                if b'python' in header:
                    result["script_type"] = "python"
                elif b'bash' in header or b'sh' in header:
                    result["script_type"] = "shell"
                else:
                    result["script_type"] = "unknown"
            else:
                result["is_script"] = False

        return result

    def _extract_strings(self, file_path: Path) -> Dict[str, Any]:
        """
        Extract and analyze strings from the file.

        Args:
            file_path: Path to the file to analyze

        Returns:
            Dictionary containing extracted strings and analysis results
        """
        result = {}

        # Use 'strings' command if available
        try:
            strings_output = subprocess.run(
                ["strings", str(file_path)],
                capture_output=True,
                text=True,
                check=True
            ).stdout.splitlines()

            # Limit to 1000 strings maximum
            strings_output = strings_output[:1000]

            # Look for suspicious strings
            suspicious_strings = []

            # Define patterns of interest
            patterns = {
                "network": ["http://", "https://", "ftp://", "ssh://", ".onion",
                           "socket", "connect(", "bind(", "listen(", "recv(", "send("],
                "crypto": ["encrypt", "decrypt", "AES", "RSA", "crypt", "hash", "sha1", "sha256"],
                "system": ["system(", "exec(", "spawn", "fork(", "cmd.exe", "/bin/sh", "/bin/bash",
                          "powershell", "registry", "regedit"],
                "file_ops": ["fopen", "CreateFile", "readdir", "opendir", "DeleteFile", "unlink"],
                "obfuscation": ["base64", "hex", "rot13", "xor", "encode", "decode", "obfuscate"],
                "persistence": ["startup", "scheduled task", "crontab", "registry", "autorun"]
            }

            # Check strings against patterns
            category_matches = {category: [] for category in patterns}
            for string in strings_output:
                for category, words in patterns.items():
                    if any(word.lower() in string.lower() for word in words):
                        category_matches[category].append(string)
                        if string not in suspicious_strings:
                            suspicious_strings.append(string)

            # Add results
            result["extracted_strings_count"] = len(strings_output)
            result["suspicious_strings_count"] = len(suspicious_strings)
            result["suspicious_strings"] = suspicious_strings[:50]  # Limit to 50 max
            result["category_matches"] = {k: v[:20] for k, v in category_matches.items() if v}  # Limit each category

        except (subprocess.SubprocessError, FileNotFoundError):
            self.logger.warning("Could not extract strings from file")
            result["strings_error"] = "Failed to extract strings"

            # Alternative method using Python for basic string extraction
            try:
                with open(file_path, 'rb') as f:
                    content = f.read()

                # Simple string extraction (very basic)
                import re
                printable = re.compile(b'[\\x20-\\x7E]{4,}')  # ASCII printable chars, at least 4 chars
                strings = [match.group().decode('ascii', errors='ignore') for match in printable.finditer(content)]

                # Limit and categorize as before
                strings = strings[:1000]
                result["extraction_method"] = "python_fallback"
                result["extracted_strings_count"] = len(strings)

                # Check against patterns
                suspicious_strings = []
                category_matches = {category: [] for category in patterns}

                for string in strings:
                    for category, words in patterns.items():
                        if any(word.lower() in string.lower() for word in words):
                            category_matches[category].append(string)
                            if string not in suspicious_strings:
                                suspicious_strings.append(string)

                result["suspicious_strings_count"] = len(suspicious_strings)
                result["suspicious_strings"] = suspicious_strings[:50]
                result["category_matches"] = {k: v[:20] for k, v in category_matches.items() if v}

            except Exception as e:
                result["strings_error"] = f"Failed to extract strings using fallback method: {e}"

        return result

    def _scan_with_yara(self, file_path: Path) -> List[Dict[str, Any]]:
        """
        Scan a file with YARA rules to identify malicious patterns.

        Args:
            file_path: Path to the file to scan

        Returns:
            List of matches with rule details
        """
        # Check if yara-python is available
        try:
            import yara
        except ImportError:
            self.logger.warning("YARA Python module not available, skipping scan")
            return []

        # Identify YARA rules directory
        yara_rules_dir = self.config.get('analysis', {}).get('yara_rules_dir')
        if not yara_rules_dir:
            # Try to find YARA rules in common locations
            possible_locations = [
                MODULE_PATH / "yara_rules",
                MODULE_PATH.parent / "forensic_tools" / "yara_rules",
                MODULE_PATH.parent / "forensics" / "static_analysis" / "common" / "yara_rules"
            ]

            for location in possible_locations:
                if location.exists():
                    yara_rules_dir = str(location)
                    break

        if not yara_rules_dir or not Path(yara_rules_dir).exists():
            self.logger.warning("YARA rules directory not found")
            return []

        matches = []
        try:
            # Try to compile all rules in the directory
            rules_files = []
            for ext in ('*.yar', '*.yara'):
                rules_files.extend(Path(yara_rules_dir).glob(f"**/{ext}"))

            if not rules_files:
                self.logger.warning(f"No YARA rule files found in {yara_rules_dir}")
                return []

            # Compile and scan with each rule file separately for better error handling
            for rule_file in rules_files:
                try:
                    rules = yara.compile(str(rule_file))
                    rule_matches = rules.match(str(file_path))

                    for match in rule_matches:
                        match_data = {
                            "rule": match.rule,
                            "namespace": match.namespace,
                            "tags": match.tags,
                            "meta": match.meta,
                            "strings": [
                                {
                                    "identifier": s[1],
                                    "data": s[2].decode('utf-8', errors='replace')[:100],
                                    "offset": s[0]
                                }
                                for s in match.strings[:10]  # Limit to first 10 strings
                            ]
                        }
                        matches.append(match_data)

                except Exception as e:
                    self.logger.warning(f"Error scanning with rule file {rule_file}: {e}")

        except Exception as e:
            self.logger.error(f"YARA scanning error: {e}")

        return matches

    def _perform_detailed_analysis(self, file_path: Path) -> Dict[str, Any]:
        """
        Perform more detailed analysis using additional tools.

        Args:
            file_path: Path to the file to analyze

        Returns:
            Dict with detailed analysis results
        """
        result = {}

        # Check if external tools are allowed
        if not self.config.get('analysis', {}).get('use_external_tools', True):
            result["detailed_analysis"] = "External tool usage disabled in configuration"
            return result

        # Check for external forensic tools
        try:
            # Try to import from forensic tools if available
            sys.path.insert(0, str(MODULE_PATH.parent))

            forensic_results = {}

            # Try to use static analysis tools if available
            try:
                from forensics.static_analysis import analyze_file, check_malware_signatures

                # Get file analysis
                analysis = analyze_file(str(file_path), include_entropy=True)
                if analysis:
                    forensic_results["static_analysis"] = analysis

                # Check signatures
                sig_check = check_malware_signatures(str(file_path))
                if sig_check:
                    forensic_results["signature_check"] = sig_check

            except ImportError:
                self.logger.debug("Static analysis module not available")

            # Try to extract metadata
            try:
                import exiftool
                with exiftool.ExifTool() as et:
                    metadata = et.get_metadata(str(file_path))
                    forensic_results["metadata"] = metadata
            except ImportError:
                # Try using subprocess if Python module not available
                try:
                    if shutil.which("exiftool"):
                        metadata = subprocess.run(
                            ["exiftool", "-json", str(file_path)],
                            capture_output=True,
                            text=True,
                            check=True
                        ).stdout
                        forensic_results["metadata"] = json.loads(metadata)
                except (subprocess.SubprocessError, json.JSONDecodeError):
                    self.logger.debug("Metadata extraction failed")

            result.update(forensic_results)

        except Exception as e:
            self.logger.warning(f"Detailed analysis error: {e}")
            result["analysis_error"] = str(e)

        return result

    def _assess_risk_level(self, analysis_result: Dict[str, Any]) -> str:
        """
        Assess the risk level of a file based on analysis results.

        Args:
            analysis_result: Analysis results dictionary

        Returns:
            Risk level (critical, high, medium, low, or unknown)
        """
        # Initialize score
        risk_score = 0

        # Check for critical indicators - immediate high risk
        if analysis_result.get("yara_matches"):
            for match in analysis_result.get("yara_matches", []):
                # Check for critical YARA rule matches
                if match.get("tags") and any("malware" in tag.lower() for tag in match.get("tags", [])):
                    return "critical"
                risk_score += 30

        # Check for high risk extensions
        if analysis_result.get("high_risk_extension"):
            risk_score += 20

        # Check for executable files
        if analysis_result.get("is_executable"):
            risk_score += 15

        # Check for suspicious strings categories
        category_scores = {
            "network": 5,
            "crypto": 10,
            "system": 15,
            "file_ops": 5,
            "obfuscation": 20,
            "persistence": 25
        }

        for category, matches in analysis_result.get("category_matches", {}).items():
            if category in category_scores and matches:
                risk_score += min(category_scores[category] * len(matches) // 2, category_scores[category] * 2)

        # Calculate final risk level
        if risk_score >= 70:
            return "critical"
        elif risk_score >= 40:
            return "high"
        elif risk_score >= 20:
            return "medium"
        elif risk_score > 0:
            return "low"
        else:
            return "unknown"

    def _get_process_info(self, pid: int) -> Dict[str, Any]:
        """
        Get information about a running process.

        Args:
            pid: Process ID

        Returns:
            Dict with process information
        """
        info = {"pid": pid}

        try:
            if psutil.pid_exists(pid):
                proc = psutil.Process(pid)
                info.update({
                    "name": proc.name(),
                    "exe": proc.exe(),
                    "cmdline": proc.cmdline(),
                    "username": proc.username(),
                    "create_time": datetime.fromtimestamp(proc.create_time()).isoformat(),
                    "status": proc.status(),
                    "memory_info": dict(proc.memory_info()._asdict()),
                    "connections": [dict(conn._asdict()) for conn in proc.connections()],
                    "open_files": [f.path for f in proc.open_files()]
                })
        except ImportError:
            # Basic fallback for systems without psutil
            if sys.platform == "win32":
                try:
                    output = subprocess.check_output(["wmic", "process", "where", f"ProcessId={pid}", "get",
                                                    "Caption,ExecutablePath,CommandLine,CreationDate"],
                                                    text=True)
                    lines = output.strip().split('\n')
                    if len(lines) > 1:
                        info["name"] = lines[1].split()[0]
                        # Parse other details if available
                except subprocess.SubprocessError:
                    pass
            else:
                try:
                    # Basic Unix process info
                    output = subprocess.check_output(["ps", "-p", str(pid), "-o", "comm,args,lstart"], text=True)
                    lines = output.strip().split('\n')
                    if len(lines) > 1:
                        parts = lines[1].split(None, 1)
                        info["name"] = parts[0]
                        if len(parts) > 1:
                            info["cmdline"] = parts[1]
                except subprocess.SubprocessError:
                    pass

        return info

    def _is_critical_process(self, process_info: Dict[str, Any]) -> bool:
        """
        Check if a process is critical to system operation.

        Args:
            process_info: Process information dictionary

        Returns:
            True if process is critical, False otherwise
        """
        # Define lists of critical process names
        critical_windows = {
            "system", "smss.exe", "csrss.exe", "wininit.exe",
            "services.exe", "lsass.exe", "winlogon.exe",
            "svchost.exe", "explorer.exe"
        }

        critical_unix = {
            "init", "systemd", "kthreadd", "kworker",
            "sshd", "bash", "sh", "zsh", "login"
        }

        name = process_info.get("name", "").lower()

        # Check against platform-specific critical process lists
        if sys.platform == "win32":
            if name in critical_windows:
                return True
        else:
            # Unix-like systems
            if name in critical_unix or name.startswith(("kworker", "systemd-")):
                return True

        return False

    def __str__(self) -> str:
        """Return string representation of the malware containment instance."""
        return f"MalwareContainment(incident_id={self.incident_id}, quarantine_dir={self.quarantine_dir})"

    def __repr__(self) -> str:
        """Return representation of the malware containment instance."""
        return self.__str__()


# Module-level function, correctly indented as it's not a class method
def main() -> int:
    """
    Command line entry point for malware containment.

    Returns:
        int: Exit code (0 for success, non-zero for error)
    """
    parser = argparse.ArgumentParser(description="Malware Containment Tool")

    # Create subparsers for different operations
    subparsers = parser.add_subparsers(dest="command", help="Command to execute")

    # Quarantine file command
    quarantine_parser = subparsers.add_parser("quarantine", help="Quarantine a suspicious file")
    quarantine_parser.add_argument("file", help="Path to file to quarantine")
    quarantine_parser.add_argument("--incident-id", help="Incident identifier")
    quarantine_parser.add_argument("--encrypt", action="store_true", help="Encrypt the file in quarantine")
    quarantine_parser.add_argument("--analyst", help="Name of analyst performing the quarantine")
    quarantine_parser.add_argument("--quarantine-dir", help="Directory for quarantined files")

    # Analyze file command
    analyze_parser = subparsers.add_parser("analyze", help="Analyze a suspicious file")
    analyze_parser.add_argument("file", help="Path to file to analyze")
    analyze_parser.add_argument("--incident-id", help="Incident identifier")
    analyze_parser.add_argument("--detailed", action="store_true", help="Perform detailed analysis")
    analyze_parser.add_argument("--output", help="Output file for analysis results")
    analyze_parser.add_argument("--analyst", help="Name of analyst performing the analysis")

    # List quarantined files command
    list_parser = subparsers.add_parser("list", help="List quarantined files")
    list_parser.add_argument("--incident-id", required=True, help="Incident identifier")
    list_parser.add_argument("--quarantine-dir", help="Directory for quarantined files")

    # Restore file command
    restore_parser = subparsers.add_parser("restore", help="Restore a quarantined file")
    restore_parser.add_argument("file", help="Path to quarantined file to restore")
    restore_parser.add_argument("--restore-path", help="Path where file should be restored")
    restore_parser.add_argument("--incident-id", required=True, help="Incident identifier")
    restore_parser.add_argument("--no-decrypt", action="store_true", help="Do not decrypt the file")
    restore_parser.add_argument("--quarantine-dir", help="Directory for quarantined files")

    # Isolate process command
    isolate_parser = subparsers.add_parser("isolate-process", help="Isolate a suspicious process")
    isolate_parser.add_argument("pid", type=int, help="Process ID to isolate")
    isolate_parser.add_argument("--method", choices=["suspend", "terminate", "isolate"],
                              help="Isolation method")
    isolate_parser.add_argument("--incident-id", help="Incident identifier")
    isolate_parser.add_argument("--force", action="store_true", help="Force operation even for critical processes")

    # Add shared arguments
    for p in [quarantine_parser, analyze_parser, list_parser, restore_parser, isolate_parser]:
        p.add_argument("--verbose", "-v", action="store_true", help="Enable verbose output")
        p.add_argument("--config", help="Path to configuration file")

    # Parse arguments
    args = parser.parse_args()

    # Configure logging
    log_level = logging.DEBUG if args.verbose else logging.INFO
    logging.basicConfig(
        level=log_level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )

    # Initialize MalwareContainment
    try:
        containment = MalwareContainment(
            incident_id=args.incident_id,
            quarantine_dir=args.quarantine_dir if hasattr(args, 'quarantine_dir') else None,
            config_path=args.config,
            analyst=args.analyst if hasattr(args, 'analyst') else None,
            log_level=log_level
        )
    except Exception as e:
        logger.error(f"Failed to initialize malware containment: {e}")
        return 1

    try:
        if args.command == "quarantine":
            result = containment.quarantine_file(
                file_path=args.file,
                encrypt=args.encrypt
            )

            if result["status"] == "success":
                print(f"File successfully quarantined: {result['quarantine_path']}")
                print(f"SHA-256: {result.get('sha256', 'N/A')}")
                return 0
            else:
                print(f"Quarantine failed: {result.get('reason', 'Unknown error')}")
                return 1

        elif args.command == "analyze":
            result = containment.analyze_file(args.file, detailed=args.detailed)

            # Output results
            if args.output:
                with open(args.output, 'w') as f:
                    json.dump(result, f, indent=2)
                print(f"Analysis results saved to {args.output}")
            else:
                # Print summary to console
                print(f"\nAnalysis Results for {args.file}")
                print(f"Risk Level: {result.get('risk_level', 'Unknown')}")
                print(f"File Type: {result.get('file_type', 'Unknown')}")
                print(f"SHA-256: {result.get('sha256', 'N/A')}")
                print(f"MD5: {result.get('md5', 'N/A')}")

                # Print YARA matches if any
                if result.get("yara_matches"):
                    print(f"\nYARA Matches: {len(result.get('yara_matches', []))}")
                    for i, match in enumerate(result.get("yara_matches", [])[:5]):
                        print(f"  {i+1}. {match.get('rule')} ({', '.join(match.get('tags', []))})")
                    if len(result.get("yara_matches", [])) > 5:
                        print(f"  ... and {len(result.get('yara_matches', [])) - 5} more")
                else:
                    print("\nNo YARA matches found")

                # Print suspicious strings
                if result.get("suspicious_strings_count", 0) > 0:
                    print(f"\nSuspicious Strings: {result.get('suspicious_strings_count')}")
                    for category, strings in result.get("category_matches", {}).items():
                        if strings:
                            print(f"  {category} ({len(strings)}): {strings[0][:50]}...")
                            if len(strings) > 1:
                                print(f"    ... and {len(strings) - 1} more")

            return 0

        elif args.command == "list":
            records = containment.list_quarantined_files()

            if records:
                print(f"\nQuarantined files for incident {args.incident_id}:")
                for i, record in enumerate(records, 1):
                    print(f"{i}. {record.get('file_name', 'Unknown')} - {record.get('timestamp', 'Unknown')}")
                    print(f"   Path: {record.get('quarantine_path', 'Unknown')}")
                    print(f"   SHA-256: {record.get('sha256', 'N/A')}")
                    print(f"   Encrypted: {record.get('encrypted', False)}")
                    print()
            else:
                print(f"No quarantined files found for incident {args.incident_id}")

            return 0

        elif args.command == "restore":
            result = containment.restore_quarantined_file(
                quarantine_path=args.file,
                restore_path=args.restore_path,
                decrypt=not args.no_decrypt
            )

            if result["status"] == "success":
                print(f"File successfully restored to: {result['restore_path']}")
                return 0
            else:
                print(f"Restore failed: {result.get('error', 'Unknown error')}")
                return 1

        elif args.command == "isolate-process":
            result = containment.isolate_process(
                pid=args.pid,
                method=args.method,
                force=args.force
            )

            if result["status"] == "success":
                print(f"Process {args.pid} successfully isolated using method: {args.method or 'default'}")
                return 0
            else:
                print(f"Process isolation failed: {result.get('error', 'Unknown error')}")
                return 1

        else:
            parser.print_help()
            return 1

    except Exception as e:
        logger.error(f"Error: {e}")
        return 1


# Module exports
__all__ = [
    'MalwareContainment',
    'MalwareContainmentError',
    'QuarantineError',
    'AnalysisError',
    'ValidationError',
    'SAFE_EXTENSIONS',
    'HIGH_RISK_EXTENSIONS'
]

if __name__ == "__main__":
    sys.exit(main())
